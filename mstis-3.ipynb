{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose a prediction Sequence:\n",
      "Source sequence:  [0.8414709848078965, 0.9092974268256817, 0.1411200080598672, -0.7568024953079282, -0.9589242746631385, -0.27941549819892586, 0.6569865987187891, 0.9893582466233818, 0.4121184852417566, -0.5440211108893698]\n",
      "Expected predicted sequence:  [0.8414709848078965, 0.9092974268256817, 0.1411200080598672, -0.7568024953079282, -0.9589242746631385, -0.27941549819892586, 0.6569865987187891, 0.9893582466233818, 0.4121184852417566, -0.5440211108893698, -0.9999902065507035, -0.5365729180004349, 0.4201670368266409]\n",
      "Number of strings in the learning matrix:  7\n",
      "Iterations:  100  |  Error:  0.823760581941293\n",
      "Iterations:  200  |  Error:  0.2774948270492599\n",
      "Iterations:  300  |  Error:  0.259416435806001\n",
      "Iterations:  400  |  Error:  0.22485914210701752\n",
      "Iterations:  500  |  Error:  0.11694787236510644\n",
      "Iterations:  600  |  Error:  0.0736519177282704\n",
      "Iterations:  700  |  Error:  0.05431817275109403\n",
      "Iterations:  800  |  Error:  0.04534366043902835\n",
      "Iterations:  900  |  Error:  0.04086743188182351\n",
      "Iterations:  1000  |  Error:  0.03834707733703415\n",
      "Iterations:  1100  |  Error:  0.03670857413986525\n",
      "Iterations:  1200  |  Error:  0.035500857297793564\n",
      "Iterations:  1300  |  Error:  0.03453046388329456\n",
      "Iterations:  1400  |  Error:  0.03371042045925932\n",
      "Iterations:  1500  |  Error:  0.03299857178073047\n",
      "Iterations:  1600  |  Error:  0.03237216158416583\n",
      "Iterations:  1700  |  Error:  0.031817121290350504\n",
      "Iterations:  1800  |  Error:  0.03132344667721086\n",
      "Iterations:  1900  |  Error:  0.0308831672086185\n",
      "Iterations:  2000  |  Error:  0.030489450360982988\n",
      "Iterations:  2100  |  Error:  0.030136212087226336\n",
      "Iterations:  2200  |  Error:  0.0298179531232232\n",
      "Iterations:  2300  |  Error:  0.02952969300839378\n",
      "Iterations:  2400  |  Error:  0.029266942565033427\n",
      "Iterations:  2500  |  Error:  0.029025687745831794\n",
      "Iterations:  2600  |  Error:  0.02880237313351417\n",
      "Iterations:  2700  |  Error:  0.02859388080209558\n",
      "Iterations:  2800  |  Error:  0.028397503793493845\n",
      "Iterations:  2900  |  Error:  0.028210915062410427\n",
      "Iterations:  3000  |  Error:  0.028032133349784317\n",
      "Iterations:  3100  |  Error:  0.027859487546787493\n",
      "Iterations:  3200  |  Error:  0.027691580963981974\n",
      "Iterations:  3300  |  Error:  0.027527256663777613\n",
      "Iterations:  3400  |  Error:  0.027365564726355724\n",
      "Iterations:  3500  |  Error:  0.027205732042447358\n",
      "Iterations:  3600  |  Error:  0.02704713498290531\n",
      "Iterations:  3700  |  Error:  0.026889275094433514\n",
      "Iterations:  3800  |  Error:  0.026731757815015245\n",
      "Iterations:  3900  |  Error:  0.026574274088770652\n",
      "Iterations:  4000  |  Error:  0.026416584682964154\n",
      "Iterations:  4100  |  Error:  0.02625850696337488\n",
      "Iterations:  4200  |  Error:  0.0260999038618061\n",
      "Iterations:  4300  |  Error:  0.02594067476513858\n",
      "Iterations:  4400  |  Error:  0.025780748063799725\n",
      "Iterations:  4500  |  Error:  0.02562007511445654\n",
      "Iterations:  4600  |  Error:  0.025458625393708686\n",
      "Iterations:  4700  |  Error:  0.02529638264392688\n",
      "Iterations:  4800  |  Error:  0.025133341837246793\n",
      "Iterations:  4900  |  Error:  0.024969506807796128\n",
      "Iterations:  5000  |  Error:  0.024804888424659718\n",
      "Iterations:  5100  |  Error:  0.02463950319840845\n",
      "Iterations:  5200  |  Error:  0.024473372232024983\n",
      "Iterations:  5300  |  Error:  0.024306520442730434\n",
      "Iterations:  5400  |  Error:  0.024138975994647368\n",
      "Iterations:  5500  |  Error:  0.02397076989359905\n",
      "Iterations:  5600  |  Error:  0.02380193570485323\n",
      "Iterations:  5700  |  Error:  0.023632509362499787\n",
      "Iterations:  5800  |  Error:  0.023462529045616177\n",
      "Iterations:  5900  |  Error:  0.023292035101651797\n",
      "Iterations:  6000  |  Error:  0.02312107000172148\n",
      "Iterations:  6100  |  Error:  0.022949678315928597\n",
      "Iterations:  6200  |  Error:  0.02277790669957206\n",
      "Iterations:  6300  |  Error:  0.02260580388326977\n",
      "Iterations:  6400  |  Error:  0.022433420661747343\n",
      "Iterations:  6500  |  Error:  0.022260809877391825\n",
      "Iterations:  6600  |  Error:  0.022088026395734085\n",
      "Iterations:  6700  |  Error:  0.021915127070849447\n",
      "Iterations:  6800  |  Error:  0.02174217069931181\n",
      "Iterations:  6900  |  Error:  0.02156921796183892\n",
      "Iterations:  7000  |  Error:  0.02139633135216492\n",
      "Iterations:  7100  |  Error:  0.021223575092971722\n",
      "Iterations:  7200  |  Error:  0.02105101503896278\n",
      "Iterations:  7300  |  Error:  0.020878718567348076\n",
      "Iterations:  7400  |  Error:  0.020706754456160662\n",
      "Iterations:  7500  |  Error:  0.020535192750955243\n",
      "Iterations:  7600  |  Error:  0.020364104620532064\n",
      "Iterations:  7700  |  Error:  0.020193562202422896\n",
      "Iterations:  7800  |  Error:  0.0200236384389451\n",
      "Iterations:  7900  |  Error:  0.019854406904688267\n",
      "Iterations:  8000  |  Error:  0.019685941626358183\n",
      "Iterations:  8100  |  Error:  0.019518316895943234\n",
      "Iterations:  8200  |  Error:  0.019351607078211392\n",
      "Iterations:  8300  |  Error:  0.01918588641357934\n",
      "Iterations:  8400  |  Error:  0.019021228817419918\n",
      "Iterations:  8500  |  Error:  0.018857707676898188\n",
      "Iterations:  8600  |  Error:  0.018695395646439766\n",
      "Iterations:  8700  |  Error:  0.018534364442942167\n",
      "Iterations:  8800  |  Error:  0.0183746846418422\n",
      "Iterations:  8900  |  Error:  0.018216425475145\n",
      "Iterations:  9000  |  Error:  0.01805965463250593\n",
      "Iterations:  9100  |  Error:  0.01790443806643791\n",
      "Iterations:  9200  |  Error:  0.017750839802685166\n",
      "Iterations:  9300  |  Error:  0.01759892175676879\n",
      "Iterations:  9400  |  Error:  0.01744874355766755\n",
      "Iterations:  9500  |  Error:  0.017300362379543598\n",
      "Iterations:  9600  |  Error:  0.017153832782370388\n",
      "Iterations:  9700  |  Error:  0.017009206562252053\n",
      "Iterations:  9800  |  Error:  0.016866532612155722\n",
      "Iterations:  9900  |  Error:  0.01672585679370754\n",
      "Iterations:  10000  |  Error:  0.016587221820620356\n",
      "Iterations:  10100  |  Error:  0.01645066715424309\n",
      "Iterations:  10200  |  Error:  0.01631622891163502\n",
      "Iterations:  10300  |  Error:  0.01618393978648339\n",
      "Iterations:  10400  |  Error:  0.0160538289830946\n",
      "Iterations:  10500  |  Error:  0.015925922163604733\n",
      "Iterations:  10600  |  Error:  0.01580024140846224\n",
      "Iterations:  10700  |  Error:  0.01567680519015872\n",
      "Iterations:  10800  |  Error:  0.01555562836009302\n",
      "Iterations:  10900  |  Error:  0.01543672214838256\n",
      "Iterations:  11000  |  Error:  0.015320094176348423\n",
      "Iterations:  11100  |  Error:  0.015205748481342166\n",
      "Iterations:  11200  |  Error:  0.015093685553505473\n",
      "Iterations:  11300  |  Error:  0.014983902383995511\n",
      "Iterations:  11400  |  Error:  0.014876392524154337\n",
      "Iterations:  11500  |  Error:  0.014771146155050697\n",
      "Iterations:  11600  |  Error:  0.014668150166774778\n",
      "Iterations:  11700  |  Error:  0.014567388246839313\n",
      "Iterations:  11800  |  Error:  0.014468840976994439\n",
      "Iterations:  11900  |  Error:  0.014372485937759144\n",
      "Iterations:  12000  |  Error:  0.014278297819933998\n",
      "Iterations:  12100  |  Error:  0.014186248542365791\n",
      "Iterations:  12200  |  Error:  0.014096307375215078\n",
      "Iterations:  12300  |  Error:  0.014008441067990722\n",
      "Iterations:  12400  |  Error:  0.013922613981608807\n",
      "Iterations:  12500  |  Error:  0.01383878822375326\n",
      "Iterations:  12600  |  Error:  0.0137569237868274\n",
      "Iterations:  12700  |  Error:  0.013676978687803753\n",
      "Iterations:  12800  |  Error:  0.013598909109307144\n",
      "Iterations:  12900  |  Error:  0.013522669541288395\n",
      "Iterations:  13000  |  Error:  0.013448212922680476\n",
      "Iterations:  13100  |  Error:  0.013375490782458513\n",
      "Iterations:  13200  |  Error:  0.013304453379561378\n",
      "Iterations:  13300  |  Error:  0.013235049841165752\n",
      "Iterations:  13400  |  Error:  0.013167228298849665\n",
      "Iterations:  13500  |  Error:  0.013100936022206437\n",
      "Iterations:  13600  |  Error:  0.013036119549528486\n",
      "Iterations:  13700  |  Error:  0.012972724815198965\n",
      "Iterations:  13800  |  Error:  0.012910697273485058\n",
      "Iterations:  13900  |  Error:  0.012849982018456952\n",
      "Iterations:  14000  |  Error:  0.012790523899795134\n",
      "Iterations:  14100  |  Error:  0.012732267634288034\n",
      "Iterations:  14200  |  Error:  0.012675157912856528\n",
      "Iterations:  14300  |  Error:  0.012619139502975064\n",
      "Iterations:  14400  |  Error:  0.01256415734639503\n",
      "Iterations:  14500  |  Error:  0.012510156652103721\n",
      "Iterations:  14600  |  Error:  0.012457082984483015\n",
      "Iterations:  14700  |  Error:  0.01240488234666222\n",
      "Iterations:  14800  |  Error:  0.01235350125907771\n",
      "Iterations:  14900  |  Error:  0.012302886833285719\n",
      "Iterations:  15000  |  Error:  0.01225298684108753\n",
      "Iterations:  15100  |  Error:  0.012203749779046336\n",
      "Iterations:  15200  |  Error:  0.012155124928503165\n",
      "Iterations:  15300  |  Error:  0.012107062411197488\n",
      "Iterations:  15400  |  Error:  0.01205951324062566\n",
      "Iterations:  15500  |  Error:  0.01201242936927856\n",
      "Iterations:  15600  |  Error:  0.01196576373190116\n",
      "Iterations:  15700  |  Error:  0.01191947028493823\n",
      "Iterations:  15800  |  Error:  0.011873504042325799\n",
      "Iterations:  15900  |  Error:  0.011827821107796004\n",
      "Iterations:  16000  |  Error:  0.01178237870386855\n",
      "Iterations:  16100  |  Error:  0.011737135197697406\n",
      "Iterations:  16200  |  Error:  0.011692050123948841\n",
      "Iterations:  16300  |  Error:  0.011647084204877657\n",
      "Iterations:  16400  |  Error:  0.011602199367774483\n",
      "Iterations:  16500  |  Error:  0.011557358759946349\n",
      "Iterations:  16600  |  Error:  0.011512526761393678\n",
      "Iterations:  16700  |  Error:  0.011467668995336695\n",
      "Iterations:  16800  |  Error:  0.011422752336744056\n",
      "Iterations:  16900  |  Error:  0.011377744919006658\n",
      "Iterations:  17000  |  Error:  0.011332616138890327\n",
      "Iterations:  17100  |  Error:  0.011287336659899066\n",
      "Iterations:  17200  |  Error:  0.011241878414168066\n",
      "Iterations:  17300  |  Error:  0.01119621460299927\n",
      "Iterations:  17400  |  Error:  0.011150319696144457\n",
      "Iterations:  17500  |  Error:  0.011104169429931735\n",
      "Iterations:  17600  |  Error:  0.011057740804322019\n",
      "Iterations:  17700  |  Error:  0.011011012078976966\n",
      "Iterations:  17800  |  Error:  0.01096396276840658\n",
      "Iterations:  17900  |  Error:  0.010916573636263983\n",
      "Iterations:  18000  |  Error:  0.010868826688835802\n",
      "Iterations:  18100  |  Error:  0.010820705167784635\n",
      "Iterations:  18200  |  Error:  0.010772193542175242\n",
      "Iterations:  18300  |  Error:  0.010723277499827459\n",
      "Iterations:  18400  |  Error:  0.010673943938015386\n",
      "Iterations:  18500  |  Error:  0.01062418095353905\n",
      "Iterations:  18600  |  Error:  0.010573977832184691\n",
      "Iterations:  18700  |  Error:  0.0105233250375814\n",
      "Iterations:  18800  |  Error:  0.010472214199464975\n",
      "Iterations:  18900  |  Error:  0.010420638101346075\n",
      "Iterations:  19000  |  Error:  0.010368590667588367\n",
      "Iterations:  19100  |  Error:  0.010316066949884541\n",
      "Iterations:  19200  |  Error:  0.010263063113129618\n",
      "Iterations:  19300  |  Error:  0.010209576420677704\n",
      "Iterations:  19400  |  Error:  0.010155605218973927\n",
      "Iterations:  19500  |  Error:  0.010101148921548198\n",
      "Iterations:  19600  |  Error:  0.010046207992356402\n",
      "Result after testing:\n",
      "Expected value:  -0.9999902065507035 | Received value:  -0.9299201505019236 Error:  -0.07007005604877992\n",
      "Expected value:  -0.5365729180004349 | Received value:  -0.74978857578912 Error:  0.213215657788685\n",
      "Expected value:  0.4201670368266409 | Received value:  0.24034564128561725 Error:  0.17982139554102367\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy\n",
    "\n",
    "def periodic(n):\n",
    "    global down\n",
    "    if (n % 2 == 0): \n",
    "        return float(0.0)\n",
    "    elif (down == 1): \n",
    "        down = 0\n",
    "        return float(1.0)     \n",
    "    elif (down == 0):\n",
    "        down = 1\n",
    "        return float(-1.0)\n",
    "\n",
    "def activation_tanh(x):\n",
    "    return math.tanh(x)\n",
    "\n",
    "def derivative_activation_tanh(x):\n",
    "    return 1.0 / pow(math.cosh(x), 2)\n",
    "\n",
    "def forward():\n",
    "    global W, v_input, WCHH, v_context_hidden, WCOH, context_output, T, v_hidden, W_, T_, output\n",
    "    for j in range(number_of_neurons):\n",
    "        S = 0.0\n",
    "        for i in range(number_of_rows):\n",
    "            S += W[i][j] * v_input[i]\n",
    "        for i in range(number_of_neurons):\n",
    "            S += WCHH[i][j] * v_context_hidden[i]\n",
    "        S += WCOH[0][j] * context_output\n",
    "        S -= T[j]\n",
    "        v_hidden[j] = activation_tanh(S)\n",
    "    S = 0.0\n",
    "    for i in range(number_of_neurons):\n",
    "        S += W_[i][0] * v_hidden[i]\n",
    "    S -= T_\n",
    "    output = activation_tanh(S)\n",
    "    for i in range(number_of_neurons):\n",
    "        v_context_hidden[i] = v_hidden[i]\n",
    "    context_output = output\n",
    "    \n",
    "def back(val):\n",
    "    global alpha, output, W, W_, v_hidden, v_input, WCHH, v_context_hidden, WCOH, context_output, T, T_\n",
    "    for i in range(number_of_neurons):\n",
    "        for j in range(number_of_rows):\n",
    "            W[j][i] -= float(alpha * (output - val)) * W_[i][0] * derivative_activation_tanh(v_hidden[i]) * v_input[j]\n",
    "        for j in range(number_of_neurons):\n",
    "            WCHH[j][i] -= float(alpha * (output - val)) * W_[i][0] * derivative_activation_tanh(v_hidden[i]) * v_context_hidden[j]\n",
    "        W_[i][0] -= float(alpha * (output - val)) * v_hidden[i]\n",
    "        WCOH[0][i] -= float(alpha * (output - val)) * W_[i][0] * derivative_activation_tanh(v_hidden[i]) * context_output\n",
    "        T[i] = float(alpha * (output - val)) * W_[i][0] * derivative_activation_tanh(v_hidden[i])\n",
    "    T_ = float(alpha * (output - val))\n",
    "\n",
    "print(\"Choose a prediction Sequence:\")\n",
    "choise = int(input(\"1. Sinus\\n2. Cosinus\\n3. Period\\n\\nChoose: \"))\n",
    "sequence_size = int(input(\"Sequence dimension: \"))\n",
    "number_of_elements = int(input(\"Number of sequence elements to predict: \"))\n",
    "down = 1\n",
    "sequence = []\n",
    "expected_sequence = []\n",
    "if (choise == 1):\n",
    "    for n in range(1, sequence_size + 1):\n",
    "        sequence.append(math.sin(n))\n",
    "    sequence = numpy.array(sequence, dtype=\"float64\").tolist()\n",
    "    for n in range(1, sequence_size + number_of_elements + 1):\n",
    "        expected_sequence.append(math.sin(n))\n",
    "    expected_sequence = numpy.array(expected_sequence, dtype=\"float64\").tolist()\n",
    "elif (choise == 2):\n",
    "    for n in range(1, sequence_size + 1):\n",
    "        sequence.append(float(math.cos(n)))\n",
    "    sequence = numpy.array(sequence, dtype=\"float64\").tolist()\n",
    "    for n in range(1, sequence_size + number_of_elements + 1):\n",
    "        expected_sequence.append(float(math.cos(n)))\n",
    "    expected_sequence = numpy.array(expected_sequence, dtype=\"float64\").tolist()\n",
    "elif (choise == 3):\n",
    "    for n in range(1, sequence_size + 1):\n",
    "        sequence.append(periodic(n))\n",
    "    sequence = numpy.array(sequence, dtype=\"float64\").tolist()\n",
    "    down = 1\n",
    "    for n in range(1, sequence_size + number_of_elements + 1):\n",
    "        expected_sequence.append(periodic(n))\n",
    "    expected_sequence = numpy.array(expected_sequence, dtype=\"float64\").tolist()\n",
    "\n",
    "print(\"Source sequence: \", sequence)\n",
    "print(\"Expected predicted sequence: \", expected_sequence)\n",
    "number_of_rows = int(input(\"Number of rows in the learning matrix: \"))\n",
    "number_of_strings_in_matrix = sequence_size - number_of_rows\n",
    "print(\"Number of strings in the learning matrix: \", number_of_strings_in_matrix)\n",
    "number_of_neurons = int(input(\"Number of neurons in the hidden layer: \"))\n",
    "alpha = float(input(\"Learning step: \"))\n",
    "max_error = float(input(\"Maximum allowable error: \"))\n",
    "N = int(input(\"Maximum number of training steps: \"))\n",
    "\n",
    "v_input = numpy.zeros(number_of_rows).tolist()\n",
    "v_hidden = numpy.zeros(number_of_neurons).tolist()\n",
    "v_output = 0.0\n",
    "v_context_hidden = numpy.zeros(number_of_neurons).tolist()\n",
    "context_output = 0.0\n",
    "T = numpy.zeros(number_of_neurons).tolist()\n",
    "T_ = 0.0\n",
    "X = numpy.zeros((number_of_strings_in_matrix, number_of_rows)).tolist()\n",
    "expected_values = []\n",
    "\n",
    "for i in range(number_of_strings_in_matrix):\n",
    "    for j in range(number_of_rows):\n",
    "        X[i][j] = sequence[i + j]\n",
    "    expected_values.append(sequence[i + number_of_rows])\n",
    "\n",
    "expected_values = numpy.array(expected_values, dtype=\"float64\").tolist()\n",
    "W = (numpy.random.rand(number_of_rows, number_of_neurons) * 2.0 - 1.0).tolist()\n",
    "WCHH = (numpy.random.rand(number_of_neurons, number_of_neurons) * 2.0 - 1.0).tolist()\n",
    "W_ = (numpy.random.rand(number_of_neurons, 1) * 2.0 - 1.0).tolist()\n",
    "WCOH = (numpy.random.rand(1, number_of_neurons) * 2.0 - 1.0).tolist()\n",
    "\n",
    "E = 100.0\n",
    "iteration = 0\n",
    "while E > max_error and iteration <= N:\n",
    "    iteration += 1\n",
    "    E = 0.0\n",
    "    for i in range(number_of_strings_in_matrix):\n",
    "        v_input = X[i]\n",
    "        forward()\n",
    "        E += (float(output - expected_values[i]) ** 2.0) / 2.0\n",
    "        back(expected_values[i])\n",
    "    if iteration % 100 == 0:\n",
    "        print(\"Iterations: \", iteration, \" |  Error: \", E)\n",
    "\n",
    "result = []\n",
    "j = sequence_size - number_of_rows\n",
    "for i in range(number_of_rows):\n",
    "    v_input[i] = sequence[j]\n",
    "    j += 1\n",
    "for i in range(number_of_elements):\n",
    "    if i > 0:\n",
    "        for j in range(number_of_rows - 1):\n",
    "            v_input[j] = v_input[j + 1]\n",
    "        v_input[number_of_rows - 1] = output\n",
    "    forward()\n",
    "    result.append(output)\n",
    "print(\"Result after testing:\")\n",
    "for i in range(number_of_elements):\n",
    "    print(\"Expected value: \", expected_sequence[sequence_size + i], \"| Received value: \", result[i], \"Error: \", expected_sequence[sequence_size + i] - result[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
